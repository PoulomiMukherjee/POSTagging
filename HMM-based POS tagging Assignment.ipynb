{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vanilla Viterbi algorithm generally faces a high loss of accuracy majorly due to the fact that when the algorithm encounters an unknown word which was not present in the training set, it assigns an incorrect tag arbitrarily. This is because, for unknown words, the emission probabilities for all candidate tags are 0, so the algorithm arbitrarily chooses (the first) tag.\n",
    "\n",
    "Using the Treebank dataset of NLTK with the 'universal' tagset, the Viterbi algorithm should be modified to solve the problem of unknown words using at least two techniques. The main objectives are:\n",
    "\n",
    "- To write the vanilla Viterbi algorithm for assigning POS tags (i.e. without dealing with unknown words)\n",
    "- To solve the problem of unknown words using at least two techniques. These techniques can use any of the approaches discussed in the class - lexicon, rule-based, probabilistic etc.\n",
    "- To compare the tagging accuracy after making these modifications with the vanilla Viterbi algorithm.\n",
    "- To list down at least three cases from the sample test file (i.e. unknown word-tag pairs) which were incorrectly tagged by the original Viterbi POS tagger and got corrected after your modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi\n",
    "\n",
    "The steps that have been followed are mentioned below:\n",
    "\n",
    "1. Build the vanilla Viterbi based POS tagger\n",
    "2. Build Modified Viterbi I using probabilistic technique\n",
    "3. Build Modified Viterbi II using rule-based backoff method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pprint, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3914\n",
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')], [('Rudolph', 'NOUN'), ('Agnew', 'NOUN'), (',', '.'), ('55', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), ('and', 'CONJ'), ('former', 'ADJ'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Consolidated', 'NOUN'), ('Gold', 'NOUN'), ('Fields', 'NOUN'), ('PLC', 'NOUN'), (',', '.'), ('was', 'VERB'), ('named', 'VERB'), ('*-1', 'X'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('British', 'ADJ'), ('industrial', 'ADJ'), ('conglomerate', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
    "print(len(nltk_data))\n",
    "print(nltk_data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "#splitting the data into train and test sets\n",
    "train_data, test_data = train_test_split(nltk_data, train_size = 0.95, test_size = 0.05, random_state = 1234)\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('This', 'DET'), ('year', 'NOUN'), (',', '.'), ('the', 'DET'), ('average', 'NOUN'), ('of', 'ADP'), ('daily', 'ADJ'), ('contracts', 'NOUN'), ('traded', 'VERB'), ('*', 'X'), ('totaled', 'VERB'), ('9,118', 'NUM'), (',', '.'), ('up', 'ADP'), ('from', 'ADP'), ('4,645', 'NUM'), ('a', 'DET'), ('year', 'NOUN'), ('earlier', 'ADJ'), ('and', 'CONJ'), ('from', 'ADP'), ('917', 'NUM'), ('in', 'ADP'), ('1984', 'NUM'), ('.', '.')], [('First', 'NOUN'), ('of', 'ADP'), ('America', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-1', 'X'), ('now', 'ADV'), ('has', 'VERB'), ('45', 'NUM'), ('banks', 'NOUN'), ('and', 'CONJ'), ('$', '.'), ('12.5', 'NUM'), ('billion', 'NUM'), ('*U*', 'X'), ('in', 'ADP'), ('assets', 'NOUN'), (',', '.'), ('announced', 'VERB'), ('an', 'DET'), ('agreement', 'NOUN'), ('*', 'X'), ('to', 'PRT'), ('acquire', 'VERB'), ('the', 'DET'), ('Peoria', 'NOUN'), (',', '.'), ('Ill.', 'NOUN'), (',', '.'), ('bank', 'NOUN'), ('holding', 'VERB'), ('company', 'NOUN'), ('in', 'ADP'), ('January', 'NOUN'), ('.', '.')], [('Meanwhile', 'ADV'), (',', '.'), ('traders', 'NOUN'), ('in', 'ADP'), ('Tokyo', 'NOUN'), ('say', 'VERB'), ('that', 'ADP'), ('the', 'DET'), ('prospect', 'NOUN'), ('of', 'ADP'), ('lower', 'ADJ'), ('U.S.', 'NOUN'), ('interest', 'NOUN'), ('rates', 'NOUN'), ('has', 'VERB'), ('spurred', 'VERB'), ('dollar', 'NOUN'), ('buying', 'VERB'), ('by', 'ADP'), ('Japanese', 'ADJ'), ('institutions', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95799"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tagged words in train set\n",
    "train_tagged_words = [tup for sent in train_data for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'year', ',', 'the', 'average', 'of', 'daily', 'contracts', 'traded', '*']\n",
      "12073\n"
     ]
    }
   ],
   "source": [
    "# checking the words present and the length of the vocabulary\n",
    "tokens = [x[0] for x in train_tagged_words]\n",
    "print(tokens[:10])\n",
    "\n",
    "V = set(tokens)\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'X', 'CONJ', 'NUM', 'PRT', 'DET', 'ADP', '.', 'PRON', 'NOUN', 'ADJ', 'ADV', 'VERB'}\n"
     ]
    }
   ],
   "source": [
    "# number of tags\n",
    "T = set([x[1] for x in train_tagged_words])\n",
    "print(len(T))\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Hidden Markov Model (HMM) algorithm, we can assign a tag (t) to a word (w) such that the likelihood of P(t/w) is maximised.\n",
    "We know that P(t/w) = P(w/t) * P(t) / P(w)\n",
    "Here,\n",
    "- P(w/t): Emission probability of a word (w) when the tag (t) is given. This can be calculated using the given formula:\n",
    " - P(w/t) = count(w, t) / count(t).\n",
    "- P(t): Transition probability or the probability of the tag (t). As per the Markov order 1 assumption, the tag (t) of a word depends of the tag of the previous word or t(n-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to determine emission probability of a word when tag is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_given_t(word, tag, train_bag = train_tagged_words):\n",
    "    tag_pairs = [(w,t) for w,t in train_bag if t == tag]\n",
    "    count_tag = len(tag_pairs)\n",
    "    count_w_given_t = len([w for w,t in tag_pairs if w == word])\n",
    "    \n",
    "    return (count_w_given_t, count_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to calculate transition probability of a tag when previous tag is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t1_given_t2(t1,t2,train_bag = train_tagged_words):\n",
    "    tag_list = [t for w,t in train_bag]\n",
    "    t1_tag_list = [x for x in tag_list if x == t2]\n",
    "    count_t1 = len(t1_tag_list)\n",
    "    count_t1_given_t2 = len([tag_list[i+1] for i in range(len(tag_list)-1) if tag_list[i] == t2 and tag_list[i+1] == t1])\n",
    "    \n",
    "    return (count_t1_given_t2, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 27471)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the output of the w_given_t function from a tagged pair in the train set \n",
    "w_given_t('company', 'NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4235, 6063)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the output of the t1_given_t2 function from the tags present in the train set\n",
    "t1_given_t2('NOUN', 'ADJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRT</th>\n",
       "      <th>DET</th>\n",
       "      <th>ADP</th>\n",
       "      <th>.</th>\n",
       "      <th>PRON</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.074842</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.184652</td>\n",
       "      <td>0.054114</td>\n",
       "      <td>0.144937</td>\n",
       "      <td>0.162816</td>\n",
       "      <td>0.056329</td>\n",
       "      <td>0.062184</td>\n",
       "      <td>0.016456</td>\n",
       "      <td>0.026108</td>\n",
       "      <td>0.204114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.041511</td>\n",
       "      <td>0.005131</td>\n",
       "      <td>0.118470</td>\n",
       "      <td>0.052705</td>\n",
       "      <td>0.033116</td>\n",
       "      <td>0.057369</td>\n",
       "      <td>0.348881</td>\n",
       "      <td>0.118937</td>\n",
       "      <td>0.055970</td>\n",
       "      <td>0.158582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.210464</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.184899</td>\n",
       "      <td>0.027051</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.035672</td>\n",
       "      <td>0.115933</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.354637</td>\n",
       "      <td>0.032402</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.018133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.014007</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.056678</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.099674</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>0.017915</td>\n",
       "      <td>0.247883</td>\n",
       "      <td>0.084039</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.402932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.046197</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.017777</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.638650</td>\n",
       "      <td>0.203652</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.039545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.035048</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.062001</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.322893</td>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.039842</td>\n",
       "      <td>0.070203</td>\n",
       "      <td>0.322893</td>\n",
       "      <td>0.105785</td>\n",
       "      <td>0.013849</td>\n",
       "      <td>0.008522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.027314</td>\n",
       "      <td>0.057772</td>\n",
       "      <td>0.080593</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.173226</td>\n",
       "      <td>0.090386</td>\n",
       "      <td>0.094070</td>\n",
       "      <td>0.065768</td>\n",
       "      <td>0.223091</td>\n",
       "      <td>0.044654</td>\n",
       "      <td>0.051932</td>\n",
       "      <td>0.088769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.093929</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.011837</td>\n",
       "      <td>0.009164</td>\n",
       "      <td>0.023291</td>\n",
       "      <td>0.040473</td>\n",
       "      <td>0.007637</td>\n",
       "      <td>0.207331</td>\n",
       "      <td>0.073692</td>\n",
       "      <td>0.032837</td>\n",
       "      <td>0.487972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.029231</td>\n",
       "      <td>0.042263</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.043974</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>0.177023</td>\n",
       "      <td>0.239307</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>0.264898</td>\n",
       "      <td>0.012231</td>\n",
       "      <td>0.017182</td>\n",
       "      <td>0.146336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.021442</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.021112</td>\n",
       "      <td>0.010886</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>0.077519</td>\n",
       "      <td>0.065809</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.698499</td>\n",
       "      <td>0.065314</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>0.012205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.023263</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.031455</td>\n",
       "      <td>0.014744</td>\n",
       "      <td>0.068480</td>\n",
       "      <td>0.118611</td>\n",
       "      <td>0.134666</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.031127</td>\n",
       "      <td>0.129751</td>\n",
       "      <td>0.081258</td>\n",
       "      <td>0.344364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.217816</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.022696</td>\n",
       "      <td>0.031216</td>\n",
       "      <td>0.133617</td>\n",
       "      <td>0.091402</td>\n",
       "      <td>0.035167</td>\n",
       "      <td>0.035321</td>\n",
       "      <td>0.110844</td>\n",
       "      <td>0.065221</td>\n",
       "      <td>0.083501</td>\n",
       "      <td>0.167622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X      CONJ       NUM       PRT       DET       ADP         .  \\\n",
       "X     0.074842  0.010759  0.002690  0.184652  0.054114  0.144937  0.162816   \n",
       "CONJ  0.008862  0.000466  0.041511  0.005131  0.118470  0.052705  0.033116   \n",
       "NUM   0.210464  0.013377  0.184899  0.027051  0.002973  0.035672  0.115933   \n",
       "PRT   0.014007  0.002280  0.056678  0.001954  0.099674  0.021173  0.041694   \n",
       "DET   0.046197  0.000484  0.022373  0.000242  0.005442  0.009191  0.017777   \n",
       "ADP   0.035048  0.000959  0.062001  0.001491  0.322893  0.016512  0.039842   \n",
       ".     0.027314  0.057772  0.080593  0.002336  0.173226  0.090386  0.094070   \n",
       "PRON  0.093929  0.004582  0.007255  0.011837  0.009164  0.023291  0.040473   \n",
       "NOUN  0.029231  0.042263  0.009537  0.043974  0.013250  0.177023  0.239307   \n",
       "ADJ   0.021442  0.016658  0.021112  0.010886  0.004948  0.077519  0.065809   \n",
       "ADV   0.023263  0.006881  0.031455  0.014744  0.068480  0.118611  0.134666   \n",
       "VERB  0.217816  0.005577  0.022696  0.031216  0.133617  0.091402  0.035167   \n",
       "\n",
       "          PRON      NOUN       ADJ       ADV      VERB  \n",
       "X     0.056329  0.062184  0.016456  0.026108  0.204114  \n",
       "CONJ  0.057369  0.348881  0.118937  0.055970  0.158582  \n",
       "NUM   0.001486  0.354637  0.032402  0.002973  0.018133  \n",
       "PRT   0.017915  0.247883  0.084039  0.009772  0.402932  \n",
       "DET   0.003749  0.638650  0.203652  0.012698  0.039545  \n",
       "ADP   0.070203  0.322893  0.105785  0.013849  0.008522  \n",
       ".     0.065768  0.223091  0.044654  0.051932  0.088769  \n",
       "PRON  0.007637  0.207331  0.073692  0.032837  0.487972  \n",
       "NOUN  0.004769  0.264898  0.012231  0.017182  0.146336  \n",
       "ADJ   0.000660  0.698499  0.065314  0.004948  0.012205  \n",
       "ADV   0.015400  0.031127  0.129751  0.081258  0.344364  \n",
       "VERB  0.035321  0.110844  0.065221  0.083501  0.167622  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating T x T matrix named M[x, y] for to store P(t(y) given t(x))\n",
    "M = np.zeros((len(T), len(T)), dtype = 'float32')\n",
    "\n",
    "for x, t2 in enumerate(list(T)):\n",
    "    for y, t1 in enumerate(list(T)): \n",
    "        M[x, y] = t1_given_t2(t1, t2)[0]/t1_given_t2(t1, t2)[1]\n",
    "\n",
    "# converting matrix into dataframe for better interpretability\n",
    "df_tag = pd.DataFrame(M, columns = list(T), index=list(T))\n",
    "df_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([tag for word,tag in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        p = [] # initialising list of probability column for a given observation\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = df_tag.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = df_tag.loc[state[-1], tag]\n",
    "                \n",
    "            # calculating emission probability and state probability\n",
    "            emission_p = w_given_t(words[key], tag)[0]/w_given_t(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Vanilla Viterbi POS Tagger on random sentences from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('``', '.'),\n",
       "  ('When', 'ADV'),\n",
       "  ('the', 'DET'),\n",
       "  ('sell', 'NOUN'),\n",
       "  ('programs', 'NOUN'),\n",
       "  ('hit', 'VERB'),\n",
       "  ('*T*-1', 'X'),\n",
       "  (',', '.'),\n",
       "  ('you', 'PRON'),\n",
       "  ('can', 'VERB'),\n",
       "  ('hear', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('order', 'NOUN'),\n",
       "  ('printers', 'NOUN'),\n",
       "  ('start', 'VERB'),\n",
       "  ('*-2', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('go', 'VERB'),\n",
       "  (\"''\", '.'),\n",
       "  ('on', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('Big', 'NOUN'),\n",
       "  ('Board', 'NOUN'),\n",
       "  ('trading', 'NOUN'),\n",
       "  ('floor', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('says', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-3', 'X'),\n",
       "  ('one', 'NUM'),\n",
       "  ('specialist', 'NOUN'),\n",
       "  ('there', 'ADV'),\n",
       "  ('.', '.')],\n",
       " [('Gunmen', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('Lebanon', 'NOUN'),\n",
       "  ('assassinated', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('Saudi', 'NOUN'),\n",
       "  ('Arabian', 'NOUN'),\n",
       "  ('Embassy', 'NOUN'),\n",
       "  ('employee', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('the', 'DET'),\n",
       "  ('pro-Iranian', 'ADJ'),\n",
       "  ('Islamic', 'NOUN'),\n",
       "  ('Jihad', 'NOUN'),\n",
       "  ('took', 'VERB'),\n",
       "  ('responsibility', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('slaying', 'NOUN'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('avenge', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('beheading', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('16', 'NUM'),\n",
       "  ('terrorists', 'NOUN'),\n",
       "  ('by', 'ADP'),\n",
       "  ('Riyadh', 'NOUN'),\n",
       "  (\"'s\", 'PRT'),\n",
       "  ('government', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('September', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Card', 'NOUN'),\n",
       "  ('holders', 'NOUN'),\n",
       "  ('who', 'PRON'),\n",
       "  ('*T*-59', 'X'),\n",
       "  ('receive', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('letter', 'NOUN'),\n",
       "  ('also', 'ADV'),\n",
       "  ('are', 'VERB'),\n",
       "  ('eligible', 'ADJ'),\n",
       "  ('for', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('sweepstakes', 'NOUN'),\n",
       "  ('with', 'ADP'),\n",
       "  ('Buick', 'NOUN'),\n",
       "  ('cars', 'NOUN'),\n",
       "  ('or', 'CONJ'),\n",
       "  ('a', 'DET'),\n",
       "  ('Hawaii', 'NOUN'),\n",
       "  ('vacation', 'NOUN'),\n",
       "  ('as', 'ADP'),\n",
       "  ('prizes', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('forthcoming', 'ADJ'),\n",
       "  ('maturity', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('November', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('10-year', 'NUM'),\n",
       "  ('Japanese', 'ADJ'),\n",
       "  ('government', 'NOUN'),\n",
       "  ('yen-denominated', 'ADJ'),\n",
       "  ('bond', 'NOUN'),\n",
       "  ('issue', 'NOUN'),\n",
       "  ('valued', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('at', 'ADP'),\n",
       "  ('about', 'ADV'),\n",
       "  ('$', '.'),\n",
       "  ('16', 'NUM'),\n",
       "  ('billion', 'NUM'),\n",
       "  ('*U*', 'X'),\n",
       "  ('has', 'VERB'),\n",
       "  ('prompted', 'VERB'),\n",
       "  ('speculation', 'NOUN'),\n",
       "  ('*ICH*-2', 'X'),\n",
       "  ('in', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('market', 'NOUN'),\n",
       "  ('that', 'ADP'),\n",
       "  ('investors', 'NOUN'),\n",
       "  ('redeeming', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('bonds', 'NOUN'),\n",
       "  ('will', 'VERB'),\n",
       "  ('diversify', 'VERB'),\n",
       "  ('into', 'ADP'),\n",
       "  ('dollar-denominated', 'ADJ'),\n",
       "  ('instruments', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('according', 'VERB'),\n",
       "  ('to', 'PRT'),\n",
       "  ('Mr.', 'NOUN'),\n",
       "  ('Madison', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Freeport-McMoRan', 'NOUN'),\n",
       "  ('Inc.', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('it', 'PRON'),\n",
       "  ('will', 'VERB'),\n",
       "  ('convert', 'VERB'),\n",
       "  ('its', 'PRON'),\n",
       "  ('Freeport-McMoRan', 'NOUN'),\n",
       "  ('Energy', 'NOUN'),\n",
       "  ('Partners', 'NOUN'),\n",
       "  ('Ltd.', 'NOUN'),\n",
       "  ('partnership', 'NOUN'),\n",
       "  ('into', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('publicly', 'ADV'),\n",
       "  ('traded', 'VERB'),\n",
       "  ('company', 'NOUN'),\n",
       "  ('through', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('exchange', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('units', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('partnership', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('common', 'ADJ'),\n",
       "  ('shares', 'NOUN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "# choosing 5 random sentences\n",
    "rndom = [random.randint(1,len(test_data)) for x in range(5)]\n",
    "\n",
    "# list of sentences\n",
    "test_run = [test_data[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "test_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  81.50230836868286\n",
      "Vanilla Viterbi accuracy (in %):  86.74698795180723\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences using Vanilla Viterbi\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "# printing time taken and accuracy\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy = (len(check)/len(tagged_seq))*100\n",
    "print(\"Vanilla Viterbi accuracy (in %): \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('the', 'DET'), (('sell', 'VERB'), ('sell', 'NOUN'))],\n",
       " [('specialist', 'NOUN'), (('there', 'DET'), ('there', 'ADV'))],\n",
       " [('in', 'ADP'), (('Lebanon', 'DET'), ('Lebanon', 'NOUN'))],\n",
       " [('Lebanon', 'NOUN'), (('assassinated', 'NOUN'), ('assassinated', 'VERB'))],\n",
       " [('the', 'DET'), (('pro-Iranian', 'NOUN'), ('pro-Iranian', 'ADJ'))],\n",
       " [('by', 'ADP'), (('Riyadh', 'DET'), ('Riyadh', 'NOUN'))],\n",
       " [('Riyadh', 'NOUN'), ((\"'s\", 'VERB'), (\"'s\", 'PRT'))],\n",
       " [('The', 'DET'), (('forthcoming', 'NOUN'), ('forthcoming', 'ADJ'))],\n",
       " [('a', 'DET'), (('10-year', 'ADJ'), ('10-year', 'NUM'))],\n",
       " [('government', 'NOUN'),\n",
       "  (('yen-denominated', 'NOUN'), ('yen-denominated', 'ADJ'))],\n",
       " [('at', 'ADP'), (('about', 'ADP'), ('about', 'ADV'))],\n",
       " [('investors', 'NOUN'), (('redeeming', 'NOUN'), ('redeeming', 'VERB'))],\n",
       " [('will', 'VERB'), (('convert', 'X'), ('convert', 'VERB'))]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the incorrectly tagged words\n",
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon checking the incorrectly tagged words, we can observe that the every time the Vanilla Viterbi algorithm encounters an unknown word, it assigns the tag of the word as 'X' since it is the first tag in the list of tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modified Viterbi I using probabilistic technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of unknown words, the emission probability becomes zero. This issue can be resolved if we use the transition probability instead of the emission probability when there is an unknown word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProbabilisticModifiedViterbi(words, train_bag = train_tagged_words):\n",
    "    T = list(set([tag for word,tag in train_bag]))\n",
    "    \n",
    "    state = []\n",
    "    for key, word in enumerate(words):\n",
    "        p = [] # initialising list of probability column for each observation\n",
    "        transition_p2 = [] # initialising list to store transition probabilities separately\n",
    "        \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = df_tag.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = df_tag.loc[state[-1], tag]\n",
    "            \n",
    "            # storing transition probabilities\n",
    "            transition_p2.append(transition_p)\n",
    "            \n",
    "            # calculating emission and state probabilities\n",
    "            emission_p = w_given_t(words[key], tag)[0]/w_given_t(words[key], tag)[1]\n",
    "            state_prob = emission_p * transition_p    \n",
    "            p.append(state_prob)\n",
    "            \n",
    "          \n",
    "        p_max = max(p)\n",
    "        max_state = T[p.index(p_max)] \n",
    "        \n",
    "        # using transition probability in case of unknown word (p_max is 0) \n",
    "        if p_max == 0:\n",
    "            p_max = max(transition_p2)\n",
    "            max_state = T[transition_p2.index(p_max)]\n",
    "                           \n",
    "        else:\n",
    "            max_state = T[p.index(p_max)] \n",
    "        \n",
    "        state.append(max_state)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  83.18158626556396\n",
      "Probabilistic Modified Viterbi accuracy (in %):  92.16867469879519\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences using Probabilistic Modified Viterbi\n",
    "start = time.time()\n",
    "tagged_seq = ProbabilisticModifiedViterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "# printing time taken and accuracy\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy = (len(check)/len(tagged_seq))*100\n",
    "print(\"Probabilistic Modified Viterbi accuracy (in %): \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see that using transition probability whenever the emission probability is zero (in case of unknown words) has caused the accuracy of the test set to improve significantly. We can further fine-tune this algorithm by using weighted transition probabilities. This is because the new algorithm will also consider the fact that some of the POS tags have a higher probability of occurence compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('X', 0.06597146107996953),\n",
       " ('CONJ', 0.022380191860040293),\n",
       " ('NUM', 0.03511518909383188),\n",
       " ('PRT', 0.03204626353093456),\n",
       " ('DET', 0.08631614108706771),\n",
       " ('ADP', 0.09798640904393574),\n",
       " ('.', 0.11618075345254125),\n",
       " ('PRON', 0.027338489963360788),\n",
       " ('NOUN', 0.286756646729089),\n",
       " ('ADJ', 0.06328876084301506),\n",
       " ('ADV', 0.03185837012912452),\n",
       " ('VERB', 0.13476132318708964)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating occurence probability of each tag\n",
    "p_tag = []\n",
    "len_train_tag = len([t for w,t in train_tagged_words])\n",
    "for tag in T:\n",
    "    temp = [tag for w,t in train_tagged_words if t == tag]\n",
    "    p_tag.append((tag,len(temp)/len_train_tag))\n",
    "p_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning the ProbabilisticModifiedViterbi function\n",
    "def ModifiedViterbi_1(words, train_bag = train_tagged_words):\n",
    "    T = list(set([tag for word,tag in train_bag]))\n",
    "    state = []\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        p = [] # initialising list of probability column for each observation\n",
    "        transition_p2 = [] # initialising list to store weighted transition probabilities\n",
    "        \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = df_tag.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = df_tag.loc[state[-1], tag]\n",
    "            \n",
    "            # weighted transition probabilities of each tag\n",
    "            tag_weight = [weight for tag_name, weight in p_tag if tag_name == tag ]\n",
    "            \n",
    "            # compute the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_weight[0]*transition_p             \n",
    "            transition_p2.append(transition_p)\n",
    "            \n",
    "            # calculating emission and state probabilities\n",
    "            emission_p = w_given_t(words[key], tag)[0]/w_given_t(words[key], tag)[1]\n",
    "            state_prob = emission_p * transition_p    \n",
    "            p.append(state_prob)\n",
    "            \n",
    "            \n",
    "        p_max = max(p)\n",
    "        max_state = T[p.index(p_max)] \n",
    "        \n",
    "        # using weighted transmission probability in case of unknown word (p_max is 0)\n",
    "        if p_max == 0:\n",
    "            p_max = max(transition_p2)\n",
    "            max_state = T[transition_p2.index(p_max)]\n",
    "                           \n",
    "        else:\n",
    "            max_state = T[p.index(p_max)] \n",
    "        \n",
    "        state.append(max_state)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  79.11043095588684\n",
      "Modified Viterbi I accuracy (in %):  92.16867469879519\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences using Modified Viterbi I\n",
    "start = time.time()\n",
    "tagged_seq = ModifiedViterbi_1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "# printing time taken and accuracy\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy = (len(check)/len(tagged_seq))*100\n",
    "print(\"Modified Viterbi I accuracy (in %): \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('printers', 'NOUN'), (('start', 'NOUN'), ('start', 'VERB'))],\n",
       " [('*T*-3', 'X'), (('one', 'NOUN'), ('one', 'NUM'))],\n",
       " [('specialist', 'NOUN'), (('there', 'DET'), ('there', 'ADV'))],\n",
       " [('Lebanon', 'NOUN'), (('assassinated', 'NOUN'), ('assassinated', 'VERB'))],\n",
       " [('the', 'DET'), (('pro-Iranian', 'NOUN'), ('pro-Iranian', 'ADJ'))],\n",
       " [('to', 'PRT'), (('avenge', 'NOUN'), ('avenge', 'VERB'))],\n",
       " [('The', 'DET'), (('forthcoming', 'NOUN'), ('forthcoming', 'ADJ'))],\n",
       " [('a', 'DET'), (('10-year', 'ADJ'), ('10-year', 'NUM'))],\n",
       " [('10-year', 'NUM'), (('Japanese', 'NOUN'), ('Japanese', 'ADJ'))],\n",
       " [('government', 'NOUN'),\n",
       "  (('yen-denominated', 'NOUN'), ('yen-denominated', 'ADJ'))],\n",
       " [('at', 'ADP'), (('about', 'ADP'), ('about', 'ADV'))],\n",
       " [('investors', 'NOUN'), (('redeeming', 'NOUN'), ('redeeming', 'VERB'))],\n",
       " [('will', 'VERB'), (('convert', 'NOUN'), ('convert', 'VERB'))]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the incorrectly tagged words\n",
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy of Modified Viterbi I has much improved compared to the Vanilla Viterbi. There are several instances where the words which were incorrectly tagged by Vanilla Viterbi has been correctly tagged by Modified Viterbi I.\n",
    "    For example:\n",
    "- The words 'printers', 'Gunmen', 'Arabian', 'Islamic', 'sweepstakes', 'Card' etc. have been correctly tagged as 'NOUN'\n",
    "- ''s' has been correctly identified as 'PRT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modified Viterbi II using rule-based backoff method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the probabilistic method, we can also modify the Vanilla Viterbi algorithm so as to backoff to a rule-based tagger every time it comes across an unknown word. We can determine the tags of most of the unknown words using a rule-based tagger which uses regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a rule-based tagger using regex\n",
    "regex = [\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),    # cardinal numbers\n",
    "    (r'.*ed$', 'VERB'),                  # past tense\n",
    "    (r'.*\\'s$', 'NOUN'),                 # possessive nouns\n",
    "    (r'.*es$', 'VERB'),                  # verb   \n",
    "    (r'.*s$', 'NOUN'),                   # plural nouns\n",
    "    (r'.*ing$', 'VERB'),                 # gerund\n",
    "    (r'.*', 'NOUN'),                     # nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),           # X    \n",
    "]\n",
    "\n",
    "Regex_tagger = nltk.RegexpTagger(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RuleBasedModifiedViterbi(words, train_bag = train_tagged_words):\n",
    "    T = list(set([tag for word,tag in train_bag]))\n",
    "    state = []\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        p = [] #initialising list of probability column for each observation\n",
    "                \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = df_tag.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = df_tag.loc[state[-1], tag]\n",
    "            \n",
    "            # computing emission and state probabilities\n",
    "            emission_p = w_given_t(words[key], tag)[0]/w_given_t(words[key], tag)[1]\n",
    "            state_prob = emission_p * transition_p    \n",
    "            p.append(state_prob)\n",
    "            \n",
    "            \n",
    "        p_max = max(p)\n",
    "        max_state = Regex_tagger.tag([word])[0][1]\n",
    "        \n",
    "        # backing of to rule-based tagger in case of unknown word (p_max is 0)\n",
    "        if p_max == 0:\n",
    "            max_state = Regex_tagger.tag([word])[0][1]\n",
    "                           \n",
    "        else:\n",
    "            if max_state != 'X':\n",
    "                max_state = T[p.index(p_max)] \n",
    "        \n",
    "        state.append(max_state)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  82.93318819999695\n",
      "Rule-based Modified Viterbi accuracy (in %):  92.7710843373494\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences using Rule-based Modified Viterbi\n",
    "start = time.time()\n",
    "tagged_seq = RuleBasedModifiedViterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "# printing time taken and accuracy\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy = (len(check)/len(tagged_seq))*100\n",
    "print(\"Rule-based Modified Viterbi accuracy (in %): \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('the', 'DET'), (('sell', 'VERB'), ('sell', 'NOUN'))],\n",
       " [('specialist', 'NOUN'), (('there', 'DET'), ('there', 'ADV'))],\n",
       " [('the', 'DET'), (('pro-Iranian', 'NOUN'), ('pro-Iranian', 'ADJ'))],\n",
       " [('the', 'DET'), (('slaying', 'VERB'), ('slaying', 'NOUN'))],\n",
       " [('to', 'PRT'), (('avenge', 'NOUN'), ('avenge', 'VERB'))],\n",
       " [('the', 'DET'), (('beheading', 'VERB'), ('beheading', 'NOUN'))],\n",
       " [('a', 'DET'), (('sweepstakes', 'VERB'), ('sweepstakes', 'NOUN'))],\n",
       " [('The', 'DET'), (('forthcoming', 'VERB'), ('forthcoming', 'ADJ'))],\n",
       " [('a', 'DET'), (('10-year', 'ADJ'), ('10-year', 'NUM'))],\n",
       " [('government', 'NOUN'),\n",
       "  (('yen-denominated', 'VERB'), ('yen-denominated', 'ADJ'))],\n",
       " [('at', 'ADP'), (('about', 'ADP'), ('about', 'ADV'))],\n",
       " [('will', 'VERB'), (('convert', 'NOUN'), ('convert', 'VERB'))]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking incorrectly tagged words\n",
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Rule-based Modified Viterbi is giving better results in terms of tagging accuracy compared to the Vanilla Viterbi as well as the Modified Viterbi I. However, we can once again fine-tune this algorithm by combining the Modified Viterbi I with the Rule-based Modified Viterbi. The final algorithm will also give an output of 'NN' instead of an 'X' when any of the rules are not satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new rule-based tagger using regex for words that do not satisfy any rules\n",
    "regex2 = [\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),    # cardinal numbers\n",
    "    (r'.*ed$', 'VERB'),                  # past tense\n",
    "    (r'.*\\'s$', 'NOUN'),                 # possessive nouns\n",
    "    (r'.*es$', 'VERB'),                  # verb   \n",
    "    (r'.*s$', 'NOUN'),                   # plural nouns\n",
    "    (r'.*ing$', 'VERB'),                 # gerund\n",
    "    (r'.*', 'NOUN'),                     # nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),           # X    \n",
    "    (r'.*', 'NN')                        # default\n",
    "]\n",
    "\n",
    "Regex_tagger2 = nltk.RegexpTagger(regex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning the RuleBasedModifiedViterbi function\n",
    "def ModifiedViterbi_2(words, train_bag = train_tagged_words):\n",
    "    T = list(set([tag for word,tag in train_bag]))\n",
    "    state = []\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        p = [] # initialising list of probability column for each observation\n",
    "        transition_p2 = [] # initialising list to store weighted transition probabilities\n",
    "        \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = df_tag.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = df_tag.loc[state[-1], tag]\n",
    "            \n",
    "            # weighted transition probabilities of each tag\n",
    "            tag_weight = [weight for tag_name, weight in p_tag if tag_name == tag ]\n",
    "            \n",
    "            # compute the transition prob weighted by tag occurance probability\n",
    "            transition_p = tag_weight[0]*transition_p             \n",
    "            transition_p2.append(transition_p)\n",
    "            \n",
    "            # calculating emission and state probabilities\n",
    "            emission_p = w_given_t(words[key], tag)[0]/w_given_t(words[key], tag)[1]\n",
    "            state_prob = emission_p * transition_p    \n",
    "            p.append(state_prob)\n",
    "            \n",
    "            \n",
    "        p_max = max(p)\n",
    "        max_state = T[p.index(p_max)] \n",
    "        \n",
    "        if p_max == 0:\n",
    "            max_state = Regex_tagger2.tag([word])[0][1]\n",
    "            \n",
    "            # finding tag with highest transition probability when any of the rules are not satisfied in the rule-based tagger\n",
    "            if max_state == 'NN':\n",
    "                p_max = max(transition_p2)\n",
    "                max_state = T[transition_p2.index(p_max)]\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            if max_state != 'X':\n",
    "                max_state = T[p.index(p_max)] \n",
    "        \n",
    "        state.append(max_state)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  77.87945890426636\n",
      "Modified Viterbi II accuracy (in %):  91.56626506024097\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences using Modified Viterbi II\n",
    "start = time.time()\n",
    "tagged_seq = ModifiedViterbi_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "# printing time taken and accuracy\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy = (len(check)/len(tagged_seq))*100\n",
    "print(\"Modified Viterbi II accuracy (in %): \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('printers', 'NOUN'), (('start', 'NOUN'), ('start', 'VERB'))],\n",
       " [('*T*-3', 'X'), (('one', 'NOUN'), ('one', 'NUM'))],\n",
       " [('specialist', 'NOUN'), (('there', 'DET'), ('there', 'ADV'))],\n",
       " [('the', 'DET'), (('pro-Iranian', 'NOUN'), ('pro-Iranian', 'ADJ'))],\n",
       " [('the', 'DET'), (('slaying', 'VERB'), ('slaying', 'NOUN'))],\n",
       " [('to', 'PRT'), (('avenge', 'NOUN'), ('avenge', 'VERB'))],\n",
       " [('the', 'DET'), (('beheading', 'VERB'), ('beheading', 'NOUN'))],\n",
       " [('a', 'DET'), (('sweepstakes', 'VERB'), ('sweepstakes', 'NOUN'))],\n",
       " [('The', 'DET'), (('forthcoming', 'VERB'), ('forthcoming', 'ADJ'))],\n",
       " [('a', 'DET'), (('10-year', 'ADJ'), ('10-year', 'NUM'))],\n",
       " [('10-year', 'NUM'), (('Japanese', 'NOUN'), ('Japanese', 'ADJ'))],\n",
       " [('government', 'NOUN'),\n",
       "  (('yen-denominated', 'VERB'), ('yen-denominated', 'ADJ'))],\n",
       " [('at', 'ADP'), (('about', 'ADP'), ('about', 'ADV'))],\n",
       " [('will', 'VERB'), (('convert', 'NOUN'), ('convert', 'VERB'))]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking incorrectly tagged words\n",
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy of Modified Viterbi II is slightly decreased than that of Modified Viterbi I. This can be due to the random samples taken from the test set. However, it is still greater than that of Vanilla Viterbi.\n",
    "- 'redeeming' and 'assassinated' has been correctly tagged as a 'VERB'\n",
    "- ''s' has been correctly assigned the tag of 'PRT'\n",
    "- 'Riyadh' and 'Lebanon' is correctly tagged as 'NOUN' by Modified Viterbi II\n",
    "\n",
    "We will have to run the modified Viterbi algorithms on the complete test set in order to make any concrete inferences in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running the Vanilla Viterbi, Modified Viterbi I and Modified Viterbi II on the complete test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tagged_words = [y[0] for x in test_data for y in x]\n",
    "test_run_base = [y for x in test_data for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  2284.6522080898285\n",
      "Vanilla Viterbi accuracy (in %):  91.0600779167521\n"
     ]
    }
   ],
   "source": [
    "# Vanilla Viterbi\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "# printing time taken and accuracy\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy = (len(check)/len(tagged_seq))*100\n",
    "print(\"Vanilla Viterbi accuracy (in %): \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  2161.5463399887085\n",
      "Modified Viterbi I accuracy (in %):  93.50010252204224\n"
     ]
    }
   ],
   "source": [
    "# Modified Viterbi I\n",
    "start = time.time()\n",
    "tagged_seq = ModifiedViterbi_1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "# printing time taken and accuracy\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy = (len(check)/len(tagged_seq))*100\n",
    "print(\"Modified Viterbi I accuracy (in %): \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  2252.8400683403015\n",
      "Modified Viterbi II accuracy (in %):  94.54582735288088\n"
     ]
    }
   ],
   "source": [
    "# Modified Viterbi II\n",
    "start = time.time()\n",
    "tagged_seq = ModifiedViterbi_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "# printing time taken and accuracy\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy = (len(check)/len(tagged_seq))*100\n",
    "print(\"Modified Viterbi II accuracy (in %): \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the accuracy of Modified Viterbi I is better than Vanilla Viterbi, we can see above that the accuracy of Modified Viterbi II is better than that of both Modified Viterbi I and Vanilla Viterbi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating tagging accuracy on sample test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to data file: D:\\upGrad\\.CONTENT\\Assignments\\NLP Assignment\n"
     ]
    }
   ],
   "source": [
    "path = input(\"Enter the path to data file: \") # Enter the path to the dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android is a mobile operating system developed by Google.',\n",
       " 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.',\n",
       " \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\",\n",
       " 'Twitter is an online news and social networking service on which users post and interact with messages known as tweets.',\n",
       " 'Before entering politics, Donald Trump was a domineering businessman and a television personality.',\n",
       " 'The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.',\n",
       " 'This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.',\n",
       " 'Show me the cheapest round trips from Dallas to Atlanta',\n",
       " 'I would like to see flights from Denver to Philadelphia.',\n",
       " 'Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.',\n",
       " 'NASA invited social media users to experience the launch of ICESAT-2 Satellite.',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = open(path+'/Test_sentences.txt').read() # the path entered above will be used to read the file\n",
    "sample_text = sample_data.splitlines()\n",
    "open(path+'/Test_sentences.txt').close()\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_words = [word for sentence in sample_text for word in sentence.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  83.1683452129364\n"
     ]
    }
   ],
   "source": [
    "# tagging the sample test sentences using Vanilla Viterbi\n",
    "start = time.time()\n",
    "Viterbi_sample_tagged_seq = Viterbi(sample_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "# printing time taken and accuracy\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'X'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'X'),\n",
       " ('Android', 'X'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'X'),\n",
       " ('worldwide', 'X'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'X'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'X'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'X'),\n",
       " ('Google', 'X'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'X'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'X'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'X'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'X'),\n",
       " ('firehose.', 'X'),\n",
       " ('Twitter', 'X'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'X'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'X'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'X'),\n",
       " ('known', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'X'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'X'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'X'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'X'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'X'),\n",
       " ('FIFA', 'X'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'X'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'X'),\n",
       " ('FIFA', 'X'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'X'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'X'),\n",
       " ('contested', 'X'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'X'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'X'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'X'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('I', 'PRON'),\n",
       " ('would', 'VERB'),\n",
       " ('like', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('see', 'VERB'),\n",
       " ('flights', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Denver', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Philadelphia.', 'X'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('price', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('flights', 'NOUN'),\n",
       " ('leaving', 'VERB'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('3', 'NUM'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('afternoon', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('arriving', 'X'),\n",
       " ('in', 'ADP'),\n",
       " ('San', 'NOUN'),\n",
       " ('Francisco.', 'X'),\n",
       " ('NASA', 'X'),\n",
       " ('invited', 'X'),\n",
       " ('social', 'ADJ'),\n",
       " ('media', 'NOUN'),\n",
       " ('users', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('experience', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('launch', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('ICESAT-2', 'X'),\n",
       " ('Satellite.', 'X')]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Viterbi_sample_tagged_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  81.76875805854797\n"
     ]
    }
   ],
   "source": [
    "# tagging the sample test sentences using Modified Viterbi II\n",
    "start = time.time()\n",
    "ModifiedViterbi_sample_tagged_seq = ModifiedViterbi_2(sample_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "# printing time taken and accuracy\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'NOUN'),\n",
       " ('Android', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'VERB'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'NUM'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'NUM'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'NOUN'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'NOUN'),\n",
       " ('firehose.', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'NOUN'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'VERB'),\n",
       " ('known', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'NOUN'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'NOUN'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'VERB'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'NOUN'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'NUM'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'NOUN'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'NOUN'),\n",
       " ('contested', 'VERB'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'NOUN'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'NOUN'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('I', 'NOUN'),\n",
       " ('would', 'VERB'),\n",
       " ('like', 'ADP'),\n",
       " ('to', 'PRT'),\n",
       " ('see', 'VERB'),\n",
       " ('flights', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Denver', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Philadelphia.', 'NOUN'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('price', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('flights', 'NOUN'),\n",
       " ('leaving', 'VERB'),\n",
       " ('Atlanta', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('3', 'NUM'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('afternoon', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('arriving', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('San', 'NOUN'),\n",
       " ('Francisco.', 'NOUN'),\n",
       " ('NASA', 'NOUN'),\n",
       " ('invited', 'VERB'),\n",
       " ('social', 'ADJ'),\n",
       " ('media', 'NOUN'),\n",
       " ('users', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('experience', 'NOUN'),\n",
       " ('the', 'DET'),\n",
       " ('launch', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('ICESAT-2', 'NOUN'),\n",
       " ('Satellite.', 'NOUN')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModifiedViterbi_sample_tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tagging accuracies in the given dataset are:\n",
    "- Vanilla Viterbi : 91.06%\n",
    "\n",
    "- Modified Viterbi I : 93.50%\n",
    "\n",
    "- Modified Viterbi II : 94.55%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that by using modified viterbi, we can significantly improve our tagging accuracy on a given text corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several cases which were incorrectly identified by the Vanilla Viterbi POS tagger but were correctly identified by the Modified Viterbi POS tagger. Some of these cases are:\n",
    "\n",
    "When using Vanilla Viterbi, we can see than some of the words have been incorrectly tagged such as:\n",
    "- '2018', '2011', and '2015' have been tagged as 'X'\n",
    "- 'NASA', 'Android', 'Google', 'worldwide', 'OS', 'smartphones', 'ICESAT-2' have been tagged as 'X'\n",
    "- 'invited' and 'arriving' has been tagged as 'X'\n",
    "\n",
    "On the other hand, the Modified Viterbi II tagger has correctly tagged the following:\n",
    "- '2018', '2011', and '2015' have been tagged as 'NUM'\n",
    "- 'NASA', 'Android', 'Google', 'worldwide', 'OS', 'smartphones', 'ICESAT-2' have been tagged as 'NOUN'\n",
    "- 'invited' and 'arriving' has been tagged as 'VERB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
